<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>漏斗蛋糕</title><link>https://tsedao.github.io/</link><description>Recent content on 漏斗蛋糕</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Mon, 27 Dec 2021 16:19:29 +0800</lastBuildDate><atom:link href="https://tsedao.github.io/index.xml" rel="self" type="application/rss+xml"/><item><title>C++ Learning Note</title><link>https://tsedao.github.io/p/c-learning-note/</link><pubDate>Mon, 27 Dec 2021 16:19:29 +0800</pubDate><guid>https://tsedao.github.io/p/c-learning-note/</guid><description>&lt;h1 id="heap-memory-and-stack-memory">Heap memory and Stack memory&lt;/h1>
&lt;ul>
&lt;li>
&lt;p>Different ways to initialize pointers&lt;/p>
&lt;ul>
&lt;li>&lt;code>int * a = &amp;amp;num;&lt;/code> create a pointer points to num on stack memory&lt;/li>
&lt;li>&lt;code>Cube * cube = new Cube;&lt;/code> create a pointer points to cube on heap memory&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>When deleting a pointer, we need to assign the pointer to &lt;code>nullptr&lt;/code> even if the the memory will be released after the function is returned&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Pointer can use &lt;code>-&amp;gt;&lt;/code> to obtain the class attribute, otherwise we need dereference and use dot (&lt;code>cube-&amp;gt;attribute&lt;/code> &amp;lt;=&amp;gt; &lt;code>(*cube).attribute)&lt;/code>&lt;/p>
&lt;/li>
&lt;li>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-c++" data-lang="c++">&lt;span class="kt">int&lt;/span> &lt;span class="o">*&lt;/span>&lt;span class="n">x&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="k">new&lt;/span> &lt;span class="kt">int&lt;/span>&lt;span class="p">;&lt;/span>
&lt;span class="kt">int&lt;/span> &lt;span class="o">&amp;amp;&lt;/span>&lt;span class="n">y&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="o">*&lt;/span>&lt;span class="n">x&lt;/span>&lt;span class="p">;&lt;/span> &lt;span class="c1">//y is the alias of heap memory stored *x
&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;/li>
&lt;/ul>
&lt;h1 id="constructors">Constructors&lt;/h1>
&lt;ul>
&lt;li>
&lt;p>Default constructor/ Customized constructor&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Copy constructor (copy constructors are invoked automatically)&lt;/p>
&lt;ul>
&lt;li>
&lt;p>Passing an object as a parameter (by value)&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Returning an object from a function (by value)&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Initializing a new object&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-c++" data-lang="c++">&lt;span class="n">Cube&lt;/span>&lt;span class="o">::&lt;/span>&lt;span class="n">Cube&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="k">const&lt;/span> &lt;span class="n">Cube&lt;/span> &lt;span class="o">&amp;amp;&lt;/span> &lt;span class="n">obj&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="p">{&lt;/span>
&lt;span class="n">length_&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">obj&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="n">length_&lt;/span>&lt;span class="p">;&lt;/span>
&lt;span class="n">std&lt;/span>&lt;span class="o">::&lt;/span>&lt;span class="n">cout&lt;/span> &lt;span class="o">&amp;lt;&amp;lt;&lt;/span> &lt;span class="s">&amp;#34;Copy constructor invoked!&amp;#34;&lt;/span> &lt;span class="o">&amp;lt;&amp;lt;&lt;/span> &lt;span class="n">std&lt;/span>&lt;span class="o">::&lt;/span>&lt;span class="n">endl&lt;/span>&lt;span class="p">;&lt;/span>
&lt;span class="p">}&lt;/span>
&lt;span class="kt">int&lt;/span> &lt;span class="nf">main&lt;/span>&lt;span class="p">()&lt;/span>
&lt;span class="p">{&lt;/span>
&lt;span class="n">Cube&lt;/span> &lt;span class="n">c&lt;/span>&lt;span class="p">;&lt;/span>
&lt;span class="n">Cube&lt;/span> &lt;span class="n">b&lt;/span>&lt;span class="p">;&lt;/span>
&lt;span class="n">Cube&lt;/span> &lt;span class="n">myCube&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">c&lt;/span>&lt;span class="p">;&lt;/span> &lt;span class="c1">// copy constructor will be called
&lt;/span>&lt;span class="c1">&lt;/span>&lt;span class="n">b&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">c&lt;/span> &lt;span class="c1">//copy constructor will not be called
&lt;/span>&lt;span class="c1">&lt;/span>&lt;span class="k">return&lt;/span> &lt;span class="mi">0&lt;/span>&lt;span class="p">;&lt;/span>
&lt;span class="p">}&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>Assign constructor&lt;/p>
&lt;ul>
&lt;li>
&lt;p>Is a public member function of the class.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Has the function name &lt;strong>operator=&lt;/strong>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Has a return value of a reference of the class’ type.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Has exactly one argument&lt;/p>
&lt;ul>
&lt;li>
&lt;p>The argument must be const reference of the class’ type.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-c++" data-lang="c++">&lt;span class="n">Cube&lt;/span> &lt;span class="o">&amp;amp;&lt;/span> &lt;span class="n">Cube&lt;/span>&lt;span class="o">::&lt;/span>&lt;span class="k">operator&lt;/span>&lt;span class="o">=&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="k">const&lt;/span> &lt;span class="n">Cube&lt;/span> &lt;span class="o">&amp;amp;&lt;/span> &lt;span class="n">obj&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="p">{&lt;/span>
&lt;span class="n">length_&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">obj&lt;/span>&lt;span class="p">.&lt;/span> &lt;span class="n">length&lt;/span>&lt;span class="p">;&lt;/span>
&lt;span class="n">std&lt;/span>&lt;span class="o">::&lt;/span>&lt;span class="n">cout&lt;/span> &lt;span class="o">&amp;lt;&amp;lt;&lt;/span> &lt;span class="s">&amp;#34;Assignment operator invoked!&amp;#34;&lt;/span>&lt;span class="o">&amp;lt;&amp;lt;&lt;/span> &lt;span class="n">std&lt;/span>&lt;span class="o">::&lt;/span>&lt;span class="n">endl&lt;/span>&lt;span class="p">;&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="o">*&lt;/span>&lt;span class="k">this&lt;/span>&lt;span class="p">;&lt;/span>
&lt;span class="p">}&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>Destructor (~). An destructor should neverbe called directly. Instead, it is automatically called when the object’s memory is being reclaimed by the system:&lt;/p>
&lt;ul>
&lt;li>If the object is on the &lt;strong>stack&lt;/strong>, when the function returns&lt;/li>
&lt;li>If the object is on the &lt;strong>heap&lt;/strong>, when &lt;strong>delete&lt;/strong> is used&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul></description></item><item><title>Docker Tutorial</title><link>https://tsedao.github.io/p/docker-tutorial/</link><pubDate>Sun, 26 Dec 2021 11:47:08 +0800</pubDate><guid>https://tsedao.github.io/p/docker-tutorial/</guid><description>&lt;h1 id="docker-installation">Docker Installation&lt;/h1>
&lt;p>Install &lt;code>docker engine&lt;/code> and &lt;code>Nvidia-docker&lt;/code> on related platforms.&lt;/p>
&lt;p>Problem of seeing CUDA11 on docker while the host CUDA version in 11.&lt;/p>
&lt;blockquote>
&lt;p>One of the primary functions of &lt;code>nvidia-docker&lt;/code> is to inject the all of NVIDIA driver libs from the host into the container so that the container will run properly with GPUs. One of these libraries is &lt;code>libcuda.so&lt;/code>. This is one of the reasons you are seeing &lt;code>nvidia-smi&lt;/code> report the driver version from your host.&lt;/p>
&lt;/blockquote>
&lt;p>Different between nvidia docker image: &lt;a class="link" href="https://blog.csdn.net/qq_31511955/article/details/115112473" target="_blank" rel="noopener"
>base/runtime/devel&lt;/a>&lt;/p>
&lt;h1 id="example-template-format-of-dockerfile">Example Template Format of Dockerfile&lt;/h1>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-dockerfile" data-lang="dockerfile">&lt;span class="k">FROM&lt;/span>&lt;span class="s"> nvidia/cuda:10.2-cudnn7-runtime-ubuntu18.04&lt;/span>&lt;span class="err">
&lt;/span>&lt;span class="err">&lt;/span>&lt;span class="k">ENV&lt;/span> &lt;span class="nv">PATH&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s2">&amp;#34;/root/miniconda3/bin:&lt;/span>&lt;span class="si">${&lt;/span>&lt;span class="nv">PATH&lt;/span>&lt;span class="si">}&lt;/span>&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="err">
&lt;/span>&lt;span class="err">&lt;/span>&lt;span class="k">ARG&lt;/span> &lt;span class="nv">PATH&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s2">&amp;#34;/root/miniconda3/bin:&lt;/span>&lt;span class="si">${&lt;/span>&lt;span class="nv">PATH&lt;/span>&lt;span class="si">}&lt;/span>&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="err">
&lt;/span>&lt;span class="err">
&lt;/span>&lt;span class="err">&lt;/span>&lt;span class="k">RUN&lt;/span> apt update &lt;span class="se">\
&lt;/span>&lt;span class="se">&lt;/span> &lt;span class="o">&amp;amp;&amp;amp;&lt;/span> apt install -y htop python3-dev wget&lt;span class="err">
&lt;/span>&lt;span class="err">
&lt;/span>&lt;span class="err">&lt;/span>&lt;span class="k">RUN&lt;/span> wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh &lt;span class="se">\
&lt;/span>&lt;span class="se">&lt;/span> &lt;span class="o">&amp;amp;&amp;amp;&lt;/span> mkdir root/.conda &lt;span class="se">\
&lt;/span>&lt;span class="se">&lt;/span> &lt;span class="o">&amp;amp;&amp;amp;&lt;/span> sh Miniconda3-latest-Linux-x86_64.sh -b &lt;span class="se">\
&lt;/span>&lt;span class="se">&lt;/span> &lt;span class="o">&amp;amp;&amp;amp;&lt;/span> rm -f Miniconda3-latest-Linux-x86_64.sh&lt;span class="err">
&lt;/span>&lt;span class="err">
&lt;/span>&lt;span class="err">&lt;/span>&lt;span class="k">RUN&lt;/span> conda create -y -n env_name &lt;span class="nv">python&lt;/span>&lt;span class="o">=&lt;/span>3.7&lt;span class="err">
&lt;/span>&lt;span class="err">
&lt;/span>&lt;span class="err">&lt;/span>&lt;span class="k">COPY&lt;/span> . home/&lt;span class="err">
&lt;/span>&lt;span class="err">
&lt;/span>&lt;span class="err">&lt;/span>&lt;span class="k">RUN&lt;/span> /bin/bash -c &lt;span class="s2">&amp;#34;cd home/ \
&lt;/span>&lt;span class="s2"> &amp;amp;&amp;amp; source activate env_name \
&lt;/span>&lt;span class="s2"> &amp;amp;&amp;amp; pip install -i https://pypi.tuna.tsinghua.edu.cn/simple -r requirements.txt&amp;#34;&lt;/span>&lt;span class="err">
&lt;/span>&lt;span class="err">
&lt;/span>&lt;span class="err">&lt;/span>&lt;span class="k">WORKDIR&lt;/span>&lt;span class="s"> home/&lt;/span>&lt;span class="err">
&lt;/span>&lt;span class="err">&lt;/span>&lt;span class="k">CMD&lt;/span> &lt;span class="p">[]&lt;/span>&lt;span class="err">
&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h1 id="build-your-customized-image-through-dockerfile">Build your customized image through Dockerfile&lt;/h1>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-shell" data-lang="shell">$ docker build -t nameOfyouImage .
&lt;/code>&lt;/pre>&lt;/div>&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-shell" data-lang="shell">$ docker run -it nameOfyouImage /bin/bash &lt;span class="se">\
&lt;/span>&lt;span class="se">&lt;/span> -v absolute path of your localhost:absolute path of your remotehost &lt;span class="se">\
&lt;/span>&lt;span class="se">&lt;/span> -p &lt;span class="o">[&lt;/span>porting&lt;span class="o">]&lt;/span> &lt;span class="se">\
&lt;/span>&lt;span class="se">&lt;/span> --rm &lt;span class="o">[&lt;/span>run the container the remove it after &lt;span class="nb">exit&lt;/span> it&lt;span class="o">]&lt;/span>
--gpus
&lt;/code>&lt;/pre>&lt;/div>&lt;p>Docker run contains docker create and run two commands, it first creates a container based on one image, then it runs /bin/bash on the container. One can use &lt;code>exit&lt;/code> to stop the container or can push &lt;code>Ctrl + P + Q&lt;/code> to detach container&amp;rsquo;s terminal and keep the container running.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-sh" data-lang="sh">$ docker ps
&lt;/code>&lt;/pre>&lt;/div>&lt;p>Checking the running container, option &lt;code>-a&lt;/code> can be used to check the exited containers.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-sh" data-lang="sh">$ docker start CONTAINERID
&lt;/code>&lt;/pre>&lt;/div>&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-sh" data-lang="sh">$ docker attach CONTAINERID
$ docker &lt;span class="nb">exec&lt;/span> -ti CONTAINERID &lt;span class="c1"># exec abd attach both require the container is running&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>Through ```docker ps `` , we could use the ID number of the container to restart it and attach to it based on the specified commends.&lt;/p>
&lt;h1 id="saving-and-loading-the-docker-image">Saving and loading the Docker image&lt;/h1>
&lt;p>Some of the servers are offline, some we may package the image we want and upload it to the remote server.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-sh" data-lang="sh">$ docker commit &lt;span class="c1"># commit the change to the image&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-sh" data-lang="sh">$ docker save myimage:latest &lt;span class="p">|&lt;/span> gzip &amp;gt; myimage_latest.tar.gz
&lt;/code>&lt;/pre>&lt;/div>&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-sh" data-lang="sh">$ docker image load -i myimage_latest.tar.gz
&lt;/code>&lt;/pre>&lt;/div>&lt;h1 id="source">Source&lt;/h1>
&lt;p>&lt;a class="link" href="https://www.youtube.com/watch?v=0qG_0CPQhpg" target="_blank" rel="noopener"
>https://www.youtube.com/watch?v=0qG_0CPQhpg&lt;/a>&lt;/p></description></item><item><title>Theory Of Statistics</title><link>https://tsedao.github.io/p/theory-of-statistics/</link><pubDate>Sun, 26 Dec 2021 10:55:34 +0800</pubDate><guid>https://tsedao.github.io/p/theory-of-statistics/</guid><description>&lt;p>LECTURE REVIEW BASED ON CUHKSZ&amp;rsquo;S THEORY OF STATISTICS (Statistical Inference George Casella)&lt;/p>
&lt;h1 id="common-family-of-distributions">Common Family of Distributions&lt;/h1>
&lt;h2 id="exponential-family">Exponential Family&lt;/h2>
&lt;p>$f(x|\theta)=h(x)c(\theta)\exp(\sum_{i}^{k}w_{i}(\theta)t_{i}(x))$&lt;/p>
&lt;ul>
&lt;li>Binomial Distribution&lt;/li>
&lt;li>Poisson Distribution&lt;/li>
&lt;li>Exponential Distribution&lt;/li>
&lt;/ul>
&lt;p>Full exponential family versus curved exponential family&lt;/p>
&lt;p>Why we need exponential family?&lt;/p>
&lt;ul>
&lt;li>Simplify calculating exceptions and variance based on $t_{i}(x)$'&lt;/li>
&lt;li>We can use k statistics instead of a large number of original samples to make an inference about the parameter $\theta$ equivalently, without losing any information. i.e., Good property of sufficiency and completeness.&lt;/li>
&lt;/ul>
&lt;p>Note: for some distribution, we need to calculate the distribution using indicator function based on its support.&lt;/p>
&lt;h2 id="location-and-scale-family">Location and Scale Family&lt;/h2>
&lt;ul>
&lt;li>Let $f(x)$ be any pdf. Then the family of pdfs $f(x-\mu)$, indexed by the parameter $\mu$ is called the location family.
&lt;ul>
&lt;li>If Z has a pdf $f(z)$, then $X=Z+\mu$ has density $f(x-\mu)$&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>Let $f(x)$ be any pdf. Then the family of pdfs $\frac{1}{\sigma}f(\frac{x}{\sigma})$ is called the scale family with standard pdf $f(x)$&lt;/li>
&lt;li>How to prove the above statement? Event equivalence!
&lt;ul>
&lt;li>${X = x } \Leftrightarrow {Z = \frac{X-\mu}{\sigma}}$&lt;/li>
&lt;li>$P(X=x)=P(Z=\frac{x-\mu}{\sigma})$&lt;/li>
&lt;li>$f_{X}(x)dx=f(\frac{x-\mu}{\sigma})dz$&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h1 id="data-reduction">Data Reduction&lt;/h1>
&lt;p>Why reduction? Summarize the information in a sample by determine a few key features of the sample values&lt;/p>
&lt;p>How to do reduction? The method that do not discard important information about unknown parameter $\theta$ and methods that successfully discard information that is irrelevant as far as gaining knowledge about $\theta$ is concerned.&lt;/p>
&lt;h2 id="sufficiency">Sufficiency&lt;/h2>
&lt;p>Definition: $P(X=x | T(X)=T(x))$ is independent of $\theta$. The conditional distribution of a sample $X$ given the value $T(X)$ does not depend on $\theta$.&lt;/p>
&lt;p>It turns out that outside the exponential family distribution, it is rare to have a sufficient statistic of smaller dimension of the sample.&lt;/p>
&lt;p>How to find sufficiency statistic?&lt;/p>
&lt;ul>
&lt;li>$\frac{p(x|\theta)}{q(T(x|\theta)}$ independent of $\theta$&lt;/li>
&lt;li>Factorization theorem $f(x|\theta)=h(x)g(T(x)|\theta)$&lt;/li>
&lt;li>Using exponential family $\sum_{i}^{n}t(X_{i})$&lt;/li>
&lt;/ul>
&lt;p>$T'(x) = r(T(x))$, if $T'$ is sufficient, then $T$ is also sufficient. The converse of the statement is false.&lt;/p>
&lt;h2 id="minimal-sufficiency-statistic">Minimal Sufficiency Statistic&lt;/h2>
&lt;p>Why M.S.S? We have many sufficiency statistics and any one-to-one function of a sufficient statistic is a sufficient statistic.&lt;/p>
&lt;p>Definition: A sufficient statistic T is called minimal sufficient statistic if, for any other sufficient statistic T', T is a function of T'.&lt;/p>
&lt;p>How to find M.S.S?&lt;/p>
&lt;ul>
&lt;li>$\frac{f(x|\theta)}{f(y|\theta)}$ is independent of $\theta$ if and only if $T(x) = T(y)$&lt;/li>
&lt;/ul>
&lt;h2 id="ancillary">Ancillary&lt;/h2>
&lt;p>Definition: A statistic S(X) whose distribution does not depend on the parameter $\theta$ is called ancillary statistic. i.e. ($P(S(X)| \theta)$ independent of $\theta$ )&lt;/p>
&lt;h2 id="completeness">Completeness&lt;/h2>
&lt;p>Definition: $E_{\theta}(g(T)) = 0$ for all $\theta \in \Theta$ implies $P_{\theta}(g(T)=0)=1$ for $\theta \in \Theta$ . Then $T(X)$ is called complete statistic&lt;/p>
&lt;p>Interpretation:&lt;/p>
&lt;ul>
&lt;li>No ancillary statistic can be constructed based on complete statistic.&lt;/li>
&lt;li>Unique unbiased estimator, i.e., $E(T(x)) =\tau(\theta)$&lt;/li>
&lt;/ul>
&lt;p>Disprove&lt;/p>
&lt;ul>
&lt;li>Construct ancillary statistic $g(T)=S(T)-E(S(T))$, $P(g(T)) \ne 0$&lt;/li>
&lt;li>Just cancel First moment&lt;/li>
&lt;/ul>
&lt;p>Prove&lt;/p>
&lt;ul>
&lt;li>Direct calculate $E(g(T))=0$, or take the derivative related to $\theta$&lt;/li>
&lt;li>Using Full exponential family i.e., d=k&lt;/li>
&lt;/ul>
&lt;p>Note:&lt;/p>
&lt;ul>
&lt;li>$T' = r(T)$, if T is complete, then T' is also complete.&lt;/li>
&lt;li>A complete statistic can be not sufficient.&lt;/li>
&lt;/ul>
&lt;h2 id="basus-theorem">Basu&amp;rsquo;s Theorem&lt;/h2>
&lt;p>T(X) is complete and minimal sufficient statistic, then T(X) is independent of every ancillary statistic.&lt;/p>
&lt;h2 id="bahadurs-theorem">Bahadur&amp;rsquo;s Theorem&lt;/h2>
&lt;p>C.S.S is in M.S.S.&lt;/p>
&lt;p>Note:&lt;/p>
&lt;ul>
&lt;li>If there exists a T(x) to be M.S.S., but not complete, then no sufficient statistic is complete.&lt;/li>
&lt;li>If there exists a T(x) such that T is C.S.S and M.S.S, then any M.S.S are also C.S.S.&lt;/li>
&lt;/ul>
&lt;h1 id="point-estimation">Point Estimation&lt;/h1>
&lt;h2 id="methods-of-finding-point-estimators">Methods of Finding Point Estimators&lt;/h2>
&lt;h3 id="method-of-moment">Method of Moment&lt;/h3>
&lt;p>Drawback: sometimes the estimator will out of range&lt;/p>
&lt;h3 id="maximum-likelihood-estimation">Maximum Likelihood Estimation&lt;/h3>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th style="text-align:center">&lt;/th>
&lt;th style="text-align:center">Scalar&lt;/th>
&lt;th style="text-align:center">Multidimension&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td style="text-align:center">Continuous&lt;/td>
&lt;td style="text-align:center">Yes (Second order sufficient condition SOSC)&lt;/td>
&lt;td style="text-align:center">Yes&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:center">Discrete&lt;/td>
&lt;td style="text-align:center">Yes&lt;/td>
&lt;td style="text-align:center">No (Discrete optimization)&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>Advantage: the range of MLE coincides the range of parameters.&lt;/p>
&lt;p>Drawback:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>Difficult to find a global maximum&lt;/p>
&lt;/li>
&lt;li>
&lt;p>numerical sensitivity. That is how sensitive the estimator to the small change in the data.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>Invariance property of MLE. i.e., MLE of $\tau(\theta)$ is $\tau(\hat{\theta})$&lt;/p>
&lt;h3 id="bayes-estimator">Bayes Estimator&lt;/h3>
&lt;p>Data: (x1,x2,&amp;hellip;xn) + Expert Knowledge $f(x|\theta) \text{ or } \pi(x)$&lt;/p>
&lt;p>Cons: controversial because it inherently embraces a subjective notion of probability. It has no guarantee of long time performance&lt;/p>
&lt;p>Posterior distribution: $\pi(\theta|x) = f(x|\theta)\pi(\theta)/ m(x)$&lt;/p>
&lt;h2 id="methods-of-evaluating-point-estimators">Methods of Evaluating Point Estimators&lt;/h2>
&lt;h3 id="mean-square-error-mse">Mean Square Error (MSE)&lt;/h3>
&lt;p>MSE = $E_{\theta}(W-\theta)^{2}=Var_{\theta}(W)+(Bias_{\theta}(W))^{2}$&lt;/p>
&lt;p>MSE is not good for scale parameter (i.e. $\sigma$ in normal distribution), since it MSE penalizes equally for overestimation and underestimation. And the scale case, 0 is a natural lower bound, so the estimation problem is not symmetric.&lt;/p>
&lt;h3 id="best-unbiased-estimator-minimize-variance-and-control-bias">Best Unbiased Estimator (Minimize variance and control bias)&lt;/h3>
&lt;p>Motivation: many times we can a estimator that is uniformly better than the other estimator. (i.e., MSE($\hat{\sigma}^{2}$)&amp;lt;MSE($S^{2}$) for any $\sigma^{2} &amp;gt; 0$). If we can find an unbiased estimator with uniformly smallest variance, a best unbiased estimator, then our task is done.&lt;/p>
&lt;ul>
&lt;li>
&lt;p>UMVUE (uniform minimum variance unbiased estimator)&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Cramer-Rao Inequality Cramer-Rao Lower Bound valid or not?&lt;/p>
&lt;p>We can specify a lower bound, say $B(\theta)$, on the variance of any unbiased estimator of $\tau(\theta)$. If we can attain such lower bound, we can say we have found a best unbiased estimator.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Attainment&lt;/p>
&lt;p>There is no guarantee that the bound is sharp.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Use of sufficiency and unbiasedness&lt;/p>
&lt;p>Rao-Blackwell gives decrease property conditioned on sufficiency&lt;/p>
&lt;p>Condition a unbiased statistic based on a sufficient statistic $T$, i.e., $\phi(T)=E(W|T)$， then $E_{\theta}\phi(T)=\tau(\theta)$ and $Var_{\theta}(\phi(T)) \leq Var_{\theta}(W)$ for all $\theta$.&lt;/p>
&lt;p>Uniqueness of best estimator&lt;/p>
&lt;blockquote>
&lt;p>DISPROVE BEST ESTIMATOR (IF IT IS NOT ATTAINED BY CRLB): If $E_{\theta}W = \tau(\theta)$, W is the best unbiased estimator of $\tau(\theta)$ if and only if $W$ is uncorrelated with all unbiased estimators of 0.&lt;/p>
&lt;/blockquote>
&lt;blockquote>
&lt;p>If T is complete and sufficient statistic, then the unbiased estimator of $\tau(\theta)$, $\phi(T)$ is uncorrelated with any unbiased estimator of 0. So that it gives the best estimator&lt;/p>
&lt;/blockquote>
&lt;/li>
&lt;/ul>
&lt;h3 id="minimize-risk-function">Minimize Risk Function&lt;/h3>
&lt;h1 id="hypothesis-test">Hypothesis test&lt;/h1>
&lt;p>Definition: A &lt;em>hypothesis&lt;/em> is a a statement about a population parameter. A hypothesis test is a rule that specifies 1. For which sample values $H_{0}$ is rejected and for which sample value $H_{0}$ is accepted to be true.&lt;/p>
&lt;h2 id="find-hypothesis-test">Find Hypothesis test&lt;/h2>
&lt;p>Frequentist view point: Compare the likelihood of H0 and H1&lt;/p>
&lt;p>Likelihood Ratio Test (LRT), Union-Intersection, Intersection-Union gives rejection region $X\in R = {\lambda(x)&amp;lt;c}$&lt;/p>
&lt;p>Bayesian view point: Compare the probability of H0 and H1&lt;/p>
&lt;h2 id="evaluate-hypothesis-test">Evaluate Hypothesis test&lt;/h2>
&lt;p>Type 1 error (incorrectly reject H0) and Type 2 error (incorrectly accept H0)&lt;/p>
&lt;p>Power function ($P_{\theta}(X \in R) = \beta(\theta)$ that quantifies both Type 1 and Type 2 error)&lt;/p>
&lt;p>Specifically, we want to control Type 1 error while minimizing Type 2 error. i.e Size alpha test &amp;lsquo;'=&amp;rsquo;' and level alpha test &amp;ldquo;$\le$&amp;rdquo; restrict c in some degree $\text{sup}&lt;em>{\theta \in \theta&lt;/em>{0}} P(X\in R) = \alpha$, control the type 1 error&lt;/p>
&lt;h3 id="most-powerful-test">Most Powerful Test&lt;/h3>
&lt;p>Size alpha test and level alpha test may not be unique. We need to minimize Type 2 error and control Type 1 error simultaneously&lt;/p>
&lt;p>UMP (uniformly most powerful) test further impose hard restriction (Type 2 error) test from level alpha test.&lt;/p>
&lt;p>Neyman-Pearson for simple hypothesis (UMP).&lt;/p>
&lt;p>Karlin Rubin for one-side hypothesis (UMP)&lt;/p>
&lt;p>Non-existence for two-side hypothesis&lt;/p>
&lt;p>Sometimes UMP does not exist, what we should do? (Two-side hypothesis)&lt;/p>
&lt;h3 id="p-value">P-value&lt;/h3>
&lt;p>Definition: P-value is the probability of getting a value of test statistic that is at least as extreme as the one representing the sample data. $P(W(X)&amp;gt;W(x)|H_{0} \text{ is true})$&lt;/p>
&lt;p>P value reports the test results on a continuous case, rather than a dichotomous case &amp;lsquo;accept&amp;rsquo; and &amp;lsquo;reject&amp;rsquo;&lt;/p>
&lt;p>P-value cannot quantify Type 2 error and the definition of extremeness is vague.&lt;/p>
&lt;p>We can construct $P(X) = \text{sup}&lt;em>{\theta \in \Theta&lt;/em>{0}}P_{\theta}(W(X) \ge W(x))$ or $P(W(X)\ge W(x) | S(X)=S(x))$ conditioned on sufficient statistic.&lt;/p>
&lt;h1 id="interval-estimation">Interval Estimation&lt;/h1>
&lt;p>Every confidence set correspond to a hypothesis test and vice versa.&lt;/p>
&lt;h2 id="methods-of-finding-interval-estimation">Methods of finding Interval Estimation&lt;/h2>
&lt;p>Inverted LRT Step 1: find LRT accept region, Step 2: turn it to explicit form, Step 3: show that exist for all $\theta$&lt;/p>
&lt;p>Pivot Quantiles&lt;/p>
&lt;h2 id="methods-of-evaluating-interval-estimation">Methods of Evaluating Interval Estimation&lt;/h2>
&lt;p>Minimize the size (length) of interval and control the coverage probability. (Solved by Lagrange multipliers with equality constraints.)&lt;/p>
&lt;p>Decision Theory. $R(\theta,c)= E_{\theta}[L(\theta, c)]=bE_{\theta}[\text{length}(C(X))]-P_{\theta}(\theta \in C(X))&lt;/p></description></item></channel></rss>