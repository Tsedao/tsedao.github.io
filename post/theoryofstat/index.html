<!doctype html><html lang=en>
<head>
<meta charset=utf-8>
<meta http-equiv=x-ua-compatible content="IE=edge,chrome=1">
<title>Theory Of Statistics - SadWet</title>
<meta name=renderer content="webkit">
<meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=1">
<meta http-equiv=cache-control content="no-transform">
<meta http-equiv=cache-control content="no-siteapp">
<meta name=theme-color content="#f8f5ec">
<meta name=msapplication-navbutton-color content="#f8f5ec">
<meta name=apple-mobile-web-app-capable content="yes">
<meta name=apple-mobile-web-app-status-bar-style content="#f8f5ec">
<meta name=author content="Tsedao"><meta name=description content="THIS IS A SIMPLIFIED LECTURE REVIEW BASED ON CUHKSZ&amp;rsquo;S THEORY OF STATISTICS (Statistical Inference George Casella)
Common Family of Distributions Exponential Family $f(x|\theta)=h(x)c(\theta)\exp(\sum_{i}^{k}w_{i}(\theta)t_{i}(x))$
 Binomial Distribution Poisson Distribution Exponential Distribution  Full exponential family (dimension k = number of parameters d) versus curved exponential family (dimension k &amp;gt; number of parameters d)
Why do we need exponential family?
 Simplify calculating exception and variance of different moments based on $t_{i}(x)$' We can use k statistics instead of a large number of original samples to make an inference about the parameter $\theta$ equivalently, without losing any information."><meta name=keywords content="Hugo,theme,even">
<meta name=generator content="Hugo 0.91.2 with theme even">
<link rel=canonical href=https://tsedao.github.io/post/theoryofstat/>
<link href=https://tsedao.github.io/post/theoryofstat/index.xml rel=alternate type=application/rss+xml title=SadWet>
<link href=https://tsedao.github.io/post/theoryofstat/index.xml rel=feed type=application/rss+xml title=SadWet>
<link rel=apple-touch-icon sizes=180x180 href=/apple-touch-icon.png>
<link rel=icon type=image/png sizes=32x32 href=/favicon-32x32.png>
<link rel=icon type=image/png sizes=16x16 href=/favicon-16x16.png>
<link rel=manifest href=/manifest.json>
<link rel=mask-icon href=/safari-pinned-tab.svg color=#5bbad5>
<script async src=//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js></script>
<link href=/sass/main.min.f92fd13721ddf72129410fd8250e73152cc6f2438082b6c0208dc24ee7c13fc4.css rel=stylesheet>
<link rel=stylesheet href=https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.css integrity="sha256-7TyXnr2YU040zfSP+rEcz29ggW4j56/ujTPwjMzyqFY=" crossorigin=anonymous>
<meta property="og:title" content="Theory Of Statistics">
<meta property="og:description" content="THIS IS A SIMPLIFIED LECTURE REVIEW BASED ON CUHKSZ&rsquo;S THEORY OF STATISTICS (Statistical Inference George Casella)
Common Family of Distributions Exponential Family $f(x|\theta)=h(x)c(\theta)\exp(\sum_{i}^{k}w_{i}(\theta)t_{i}(x))$
 Binomial Distribution Poisson Distribution Exponential Distribution  Full exponential family (dimension k = number of parameters d) versus curved exponential family (dimension k > number of parameters d)
Why do we need exponential family?
 Simplify calculating exception and variance of different moments based on $t_{i}(x)$' We can use k statistics instead of a large number of original samples to make an inference about the parameter $\theta$ equivalently, without losing any information.">
<meta property="og:type" content="article">
<meta property="og:url" content="https://tsedao.github.io/post/theoryofstat/"><meta property="article:section" content="post">
<meta property="article:published_time" content="2021-12-26T10:55:34+08:00">
<meta property="article:modified_time" content="2021-12-26T10:55:34+08:00">
<meta itemprop=name content="Theory Of Statistics">
<meta itemprop=description content="THIS IS A SIMPLIFIED LECTURE REVIEW BASED ON CUHKSZ&rsquo;S THEORY OF STATISTICS (Statistical Inference George Casella)
Common Family of Distributions Exponential Family $f(x|\theta)=h(x)c(\theta)\exp(\sum_{i}^{k}w_{i}(\theta)t_{i}(x))$
 Binomial Distribution Poisson Distribution Exponential Distribution  Full exponential family (dimension k = number of parameters d) versus curved exponential family (dimension k > number of parameters d)
Why do we need exponential family?
 Simplify calculating exception and variance of different moments based on $t_{i}(x)$' We can use k statistics instead of a large number of original samples to make an inference about the parameter $\theta$ equivalently, without losing any information."><meta itemprop=datePublished content="2021-12-26T10:55:34+08:00">
<meta itemprop=dateModified content="2021-12-26T10:55:34+08:00">
<meta itemprop=wordCount content="1428">
<meta itemprop=keywords content><meta name=twitter:card content="summary">
<meta name=twitter:title content="Theory Of Statistics">
<meta name=twitter:description content="THIS IS A SIMPLIFIED LECTURE REVIEW BASED ON CUHKSZ&rsquo;S THEORY OF STATISTICS (Statistical Inference George Casella)
Common Family of Distributions Exponential Family $f(x|\theta)=h(x)c(\theta)\exp(\sum_{i}^{k}w_{i}(\theta)t_{i}(x))$
 Binomial Distribution Poisson Distribution Exponential Distribution  Full exponential family (dimension k = number of parameters d) versus curved exponential family (dimension k > number of parameters d)
Why do we need exponential family?
 Simplify calculating exception and variance of different moments based on $t_{i}(x)$' We can use k statistics instead of a large number of original samples to make an inference about the parameter $\theta$ equivalently, without losing any information."><!--[if lte IE 9]><script src=https://cdnjs.cloudflare.com/ajax/libs/classlist/1.1.20170427/classList.min.js></script><![endif]--><!--[if lt IE 9]><script src=https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js></script>
<script src=https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js></script><![endif]-->
<script type=text/x-mathjax-config> MathJax.Hub.Config({ TeX: { equationNumbers: { autoNumber: "all" } } }); </script>
<script type=text/x-mathjax-config>
 MathJax.Hub.Config({
   tex2jax: {
     inlineMath: [ ['$','$'], ["\\(","\\)"] ],
     processEscapes: true
   }
 });
</script>
<script type=text/javascript async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML"></script>
</head>
<body>
<div id=mobile-navbar class=mobile-navbar>
<div class=mobile-header-logo>
<a href=/ class=logo>SadWet</a>
</div>
<div class=mobile-navbar-icon>
<span></span>
<span></span>
<span></span>
</div>
</div>
<nav id=mobile-menu class="mobile-menu slideout-menu">
<ul class=mobile-menu-list>
<a href=/page/about/>
<li class=mobile-menu-item>About</li>
</a><a href=/>
<li class=mobile-menu-item>Home</li>
</a><a href=/post/>
<li class=mobile-menu-item>Archives</li>
</a><a href=/tags/>
<li class=mobile-menu-item>Tags</li>
</a><a href=/categories/>
<li class=mobile-menu-item>Categories</li>
</a><a href=/search/>
<li class=mobile-menu-item>Search</li>
</a>
</ul>
</nav>
<div class=container id=mobile-panel>
<header id=header class=header>
<div class=logo-wrapper>
<a href=/ class=logo>SadWet</a>
</div>
<nav class=site-navbar>
<ul id=menu class=menu>
<li class=menu-item>
<a class=menu-item-link href=/page/about/>About</a>
</li><li class=menu-item>
<a class=menu-item-link href=/>Home</a>
</li><li class=menu-item>
<a class=menu-item-link href=/post/>Archives</a>
</li><li class=menu-item>
<a class=menu-item-link href=/tags/>Tags</a>
</li><li class=menu-item>
<a class=menu-item-link href=/categories/>Categories</a>
</li><li class=menu-item>
<a class=menu-item-link href=/search/>Search</a>
</li>
</ul>
</nav>
</header>
<main id=main class=main>
<div class=content-wrapper>
<div id=content class=content>
<article class=post>
<header class=post-header>
<h1 class=post-title>Theory Of Statistics</h1>
<div class=post-meta>
<span class=post-time> 2021-12-26 </span>
<div class=post-category>
<a href=/categories/stat/> Stat </a>
<a href=/categories/math/> Math </a>
</div>
<span id=busuanzi_container_page_pv class=more-meta> <span id=busuanzi_value_page_pv><img src=/img/spinner.svg alt=spinner.svg></span> times read </span>
</div>
</header>
<div class=post-toc id=post-toc>
<h2 class=post-toc-title>Contents</h2>
<div class="post-toc-content always-active">
<nav id=TableOfContents>
<ul>
<li><a href=#common-family-of-distributions>Common Family of Distributions</a>
<ul>
<li><a href=#exponential-family>Exponential Family</a></li>
<li><a href=#location-and-scale-family>Location and Scale Family</a></li>
</ul>
</li>
<li><a href=#data-reduction>Data Reduction</a>
<ul>
<li><a href=#sufficiency>Sufficiency</a></li>
<li><a href=#minimal-sufficiency-statistic>Minimal Sufficiency Statistic</a></li>
<li><a href=#ancillary>Ancillary</a></li>
<li><a href=#completeness>Completeness</a></li>
<li><a href=#basus-theorem>Basu&rsquo;s Theorem</a></li>
<li><a href=#bahadurs-theorem>Bahadur&rsquo;s Theorem</a></li>
</ul>
</li>
<li><a href=#point-estimation>Point Estimation</a>
<ul>
<li><a href=#methods-of-finding-point-estimators>Methods of Finding Point Estimators</a>
<ul>
<li><a href=#method-of-moment>Method of Moment</a></li>
<li><a href=#maximum-likelihood-estimation>Maximum Likelihood Estimation</a></li>
<li><a href=#bayes-estimator>Bayes Estimator</a></li>
</ul>
</li>
<li><a href=#methods-of-evaluating-point-estimators>Methods of Evaluating Point Estimators</a>
<ul>
<li><a href=#mean-square-error-mse>Mean Square Error (MSE)</a></li>
<li><a href=#best-unbiased-estimator-minimize-variance-and-control-bias>Best Unbiased Estimator (Minimize variance and control bias)</a></li>
<li><a href=#minimize-risk-function>Minimize Risk Function</a></li>
</ul>
</li>
</ul>
</li>
<li><a href=#hypothesis-test>Hypothesis test</a>
<ul>
<li><a href=#find-hypothesis-test>Find Hypothesis test</a></li>
<li><a href=#evaluate-hypothesis-test>Evaluate Hypothesis test</a>
<ul>
<li><a href=#power-function>Power function</a></li>
<li><a href=#most-powerful-test>Most Powerful Test</a></li>
<li><a href=#p-value>P-value</a></li>
</ul>
</li>
</ul>
</li>
<li><a href=#interval-estimation>Interval Estimation</a>
<ul>
<li><a href=#methods-of-finding-interval-estimation>Methods of finding Interval Estimation</a></li>
<li><a href=#methods-of-evaluating-interval-estimation>Methods of Evaluating Interval Estimation</a></li>
</ul>
</li>
</ul>
</nav>
</div>
</div>
<div class=post-content>
<p>THIS IS A SIMPLIFIED LECTURE REVIEW BASED ON CUHKSZ&rsquo;S THEORY OF STATISTICS (Statistical Inference George Casella)</p>
<h1 id=common-family-of-distributions>Common Family of Distributions</h1>
<h2 id=exponential-family>Exponential Family</h2>
<p>$f(x|\theta)=h(x)c(\theta)\exp(\sum_{i}^{k}w_{i}(\theta)t_{i}(x))$</p>
<ul>
<li>Binomial Distribution</li>
<li>Poisson Distribution</li>
<li>Exponential Distribution</li>
</ul>
<p>Full exponential family (dimension k = number of parameters d) versus curved exponential family (dimension k > number of parameters d)</p>
<p>Why do we need exponential family?</p>
<ul>
<li>Simplify calculating exception and variance of different moments based on $t_{i}(x)$'</li>
<li>We can use k statistics instead of a large number of original samples to make an inference about the parameter $\theta$ equivalently, without losing any information. i.e., Good property of sufficiency and completeness.</li>
</ul>
<p>Note: for some distribution, we need to recalculate its pdf or pmf using indicator function based on its support.</p>
<h2 id=location-and-scale-family>Location and Scale Family</h2>
<ul>
<li>Let $f(x)$ be any pdf. Then the family of pdfs $f(x-\mu)$, indexed by the parameter $\mu$ is called the location family.
<ul>
<li>If Z has a pdf $f(z)$, then $X=Z+\mu$ has density $f(x-\mu)$</li>
</ul>
</li>
<li>Let $f(x)$ be any pdf. Then the family of pdfs $\frac{1}{\sigma}f(\frac{x}{\sigma})$ is called the scale family with standard pdf $f(x)$</li>
<li>How to prove the above statement? Event equivalence!
<ul>
<li>${X = x } \Leftrightarrow {Z = \frac{X-\mu}{\sigma}}$</li>
<li>$P(X=x)=P(Z=\frac{x-\mu}{\sigma})$</li>
<li>$f_{X}(x)dx=f(\frac{x-\mu}{\sigma})dz$</li>
</ul>
</li>
</ul>
<h1 id=data-reduction>Data Reduction</h1>
<p>Why reduction? Summarize the information in a sample by determining a few key features of the sample values</p>
<p>How to do reduction? The method that do not discard important information about unknown parameter $\theta$ and methods that successfully discard information that is irrelevant as far as gaining knowledge about $\theta$ is concerned.</p>
<h2 id=sufficiency>Sufficiency</h2>
<p><strong>Definition</strong>: $P(X=x | T(X)=T(x))$ is independent of $\theta$. The conditional distribution of a sample $X$ given the value $T(X)$ does not depend on $\theta$.</p>
<p>It turns out that outside the exponential family distribution, it is rare to have a sufficient statistic of smaller dimension of the sample.</p>
<p>How to find sufficiency statistic?</p>
<ul>
<li>$\frac{p(x|\theta)}{q(T(x|\theta)}$ independent of $\theta$</li>
<li>Factorization theorem $f(x|\theta)=h(x)g(T(x)|\theta)$</li>
<li>Using exponential family $\sum_{i}^{n}t(X_{i})$</li>
</ul>
<p>$T'(x) = r(T(x))$, if $T'$ is sufficient, then $T$ is also sufficient. The converse of the statement is false.</p>
<h2 id=minimal-sufficiency-statistic>Minimal Sufficiency Statistic</h2>
<p>Why we need Minimal Sufficiency Statistic (M.S.S)? Since we have already many sufficiency statistics and any one-to-one function of a sufficient statistic is a sufficient statistic. Among these sufficient statistic, we want to find one unique sufficient statistic that is a function of another sufficient statistic.</p>
<p>Definition: A sufficient statistic T is called minimal sufficient statistic if, for any other sufficient statistic T', T is a function of T'.</p>
<p>How to find M.S.S?</p>
<ul>
<li>$\frac{f(x|\theta)}{f(y|\theta)}$ is independent of $\theta$ if and only if $T(x) = T(y)$</li>
</ul>
<h2 id=ancillary>Ancillary</h2>
<p><strong>Definition</strong>: A statistic S(X) whose distribution does not depend on the parameter $\theta$ is called ancillary statistic. (i.e. $P(S(X)| \theta)$ independent of $\theta$ )</p>
<h2 id=completeness>Completeness</h2>
<p><strong>Definition</strong>: For $g(T)$ satisfies $E_{\theta}(g(T)) = 0$ for all $\theta \in \Theta$ implies $P_{\theta}(g(T)=0)=1$ for $\theta \in \Theta$ . Then $T(X)$ is called complete statistic</p>
<p><strong>Interpretation:</strong></p>
<ul>
<li>No ancillary statistic can be constructed based on complete statistic.</li>
<li>Unique unbiased estimator, i.e., $E(T(x)) =\tau(\theta)$ if $T$ is a complete sufficient statistic</li>
</ul>
<p><strong>Disprove Completeness:</strong></p>
<ul>
<li>Construct ancillary statistic $g(T)=S(T)-E(S(T))$, $P(g(T)) \ne 0$</li>
<li>Just cancel First moment i.e. $E[h_{1}(T)]=E[h_{2}(T)]$, $g(t)=E[h_{1}(T)]-E[h_{2}(T)]$</li>
</ul>
<p><strong>Prove</strong></p>
<ul>
<li>Direct calculate $E(g(T))=0$, or take the derivative related to $\theta$</li>
<li>Using the nice property of Full exponential family i.e., d=k</li>
</ul>
<p><strong>Property of Complete Statistic:</strong></p>
<ul>
<li>$T' = r(T)$, if T is complete, then T' is also complete.</li>
<li>A complete statistic can be not sufficient.</li>
</ul>
<h2 id=basus-theorem>Basu&rsquo;s Theorem</h2>
<p>T(X) is complete and minimal sufficient statistic, then T(X) is independent of every ancillary statistic.</p>
<h2 id=bahadurs-theorem>Bahadur&rsquo;s Theorem</h2>
<p>C.S.S is in M.S.S.</p>
<p>There exists only two situation:</p>
<ul>
<li>If there exists a T(x) to be M.S.S., but not complete, then no sufficient statistic is complete.</li>
<li>If there exists a T(x) such that T is C.S.S and M.S.S, then any M.S.S are also C.S.S.</li>
</ul>
<h1 id=point-estimation>Point Estimation</h1>
<h2 id=methods-of-finding-point-estimators>Methods of Finding Point Estimators</h2>
<h3 id=method-of-moment>Method of Moment</h3>
<p><strong>Drawback</strong>: sometimes the estimator will out of range and lack of numerical stability (i.e., a small change in the sample will lead to a huge change in the estimator.)</p>
<h3 id=maximum-likelihood-estimation>Maximum Likelihood Estimation</h3>
<table>
<thead>
<tr>
<th style=text-align:center></th>
<th style=text-align:center>Scalar</th>
<th style=text-align:center>Multidimension</th>
</tr>
</thead>
<tbody>
<tr>
<td style=text-align:center>Continuous</td>
<td style=text-align:center>Yes (Second order sufficient condition SOSC)</td>
<td style=text-align:center>Yes</td>
</tr>
<tr>
<td style=text-align:center>Discrete</td>
<td style=text-align:center>Yes</td>
<td style=text-align:center>No (Discrete optimization)</td>
</tr>
</tbody>
</table>
<p><strong>Advantage:</strong> the range of MLE coincides the range of parameters.</p>
<p><strong>Drawback:</strong></p>
<ul>
<li>
<p>Difficult to find a global maximum</p>
</li>
<li>
<p>numerical sensitivity. That is how sensitive the estimator to the small change in the data.</p>
</li>
</ul>
<p>Invariance property of MLE. i.e., MLE of $\tau(\theta)$ is $\tau(\hat{\theta})$</p>
<h3 id=bayes-estimator>Bayes Estimator</h3>
<p>Data: (x1,x2,&mldr;xn) + Expert Knowledge $f(x|\theta)$ or $\pi(x)$</p>
<p><strong>Cons</strong>: controversial because it inherently embraces a subjective notion of probability. It has no guarantee of long time performance</p>
<p>Posterior distribution: $\pi(\theta|x) = f(x|\theta)\pi(\theta)/ m(x)$</p>
<p>$\pi(x)$ Is said to conjugate to $f(x|\theta)$, if $\pi(\theta|x)$ is in the same distribution family as $\pi(x)$</p>
<h2 id=methods-of-evaluating-point-estimators>Methods of Evaluating Point Estimators</h2>
<h3 id=mean-square-error-mse>Mean Square Error (MSE)</h3>
<p>MSE = $E_{\theta}(W-\theta)^{2}=Var_{\theta}(W)+(Bias_{\theta}(W))^{2}$</p>
<p>MSE is not good for scale parameter (i.e. $\sigma$ in normal distribution), since it MSE penalizes equally for overestimation and underestimation. And the scale case, 0 is a natural lower bound, so the estimation problem is not symmetric.</p>
<h3 id=best-unbiased-estimator-minimize-variance-and-control-bias>Best Unbiased Estimator (Minimize variance and control bias)</h3>
<p><strong>Motivation:</strong> many times we can a estimator that is uniformly better than the other estimator. (i.e., MSE($\hat{\sigma}^{2}$)&lt;MSE($S^{2}$) for any $\sigma^{2} > 0$). If we can find an unbiased estimator with uniformly smallest variance, a best unbiased estimator, then our task is done.</p>
<ul>
<li>
<p>UMVUE (uniform minimum variance unbiased estimator)</p>
</li>
<li>
<p>Cramer-Rao Inequality Cramer-Rao Lower Bound valid or not?</p>
<p>We can specify a lower bound, say $B(\theta)$, on the variance of any unbiased estimator of $\tau(\theta)$. If we can attain such lower bound, we can say we have found a best unbiased estimator.</p>
</li>
<li>
<p>Attainment</p>
<p>Since sometimes there is no guarantee that the bound is sharp, we need to find out wether we can attain the Lower bound or not.</p>
</li>
<li>
<p>Use of sufficiency and unbiasedness</p>
<p>Rao-Blackwell gives decrease property conditioned on sufficiency</p>
<p>Condition a unbiased statistic based on a sufficient statistic $T$, i.e., $\phi(T)=E(W|T)$， then $E_{\theta}\phi(T)=\tau(\theta)$ and $Var_{\theta}(\phi(T)) \leq Var_{\theta}(W)$ for all $\theta$.</p>
<p>Uniqueness of best estimator</p>
<blockquote>
<p>DISPROVE BEST ESTIMATOR (IF IT IS NOT ATTAINED BY CRLB): If $E_{\theta}W = \tau(\theta)$, W is the best unbiased estimator of $\tau(\theta)$ if and only if $W$ is uncorrelated with all unbiased estimators of 0.</p>
</blockquote>
<blockquote>
<p>If T is complete and sufficient statistic, then $E(W|T)$ is the best unbiased estimator of $\tau(\theta)$, since $\phi(T)$ is uncorrelated with any unbiased estimator of 0. So that it gives the best estimator</p>
</blockquote>
</li>
</ul>
<h3 id=minimize-risk-function>Minimize Risk Function</h3>
<h1 id=hypothesis-test>Hypothesis test</h1>
<p><strong>Definition</strong>: A <em>hypothesis</em> is a a statement about a population parameter. A hypothesis test is a rule that specifies 1. For which sample values $H_{0}$ is rejected and for which sample value $H_{0}$ is accepted to be true.</p>
<h2 id=find-hypothesis-test>Find Hypothesis test</h2>
<p>Frequentist view point: Compare the likelihood of H0 and H1. Likelihood Ratio Test (LRT), Union-Intersection, Intersection-Union gives rejection region $X\in R = {\lambda(x)&lt;c}$</p>
<p>Bayesian view point: Compare the probability of H0 and H1</p>
<h2 id=evaluate-hypothesis-test>Evaluate Hypothesis test</h2>
<p>Generally, we have to control Type 1 error (incorrectly reject H0) and Type 2 error (incorrectly accept H0)</p>
<h3 id=power-function>Power function</h3>
<ul>
<li>Power function $P_{\theta}(X \in R) = \beta(\theta)$ that quantifies both Type 1 and Type 2 error)
<ul>
<li>Specifically, we want to control Type 1 error while minimizing Type 2 error. i.e Size alpha test &lsquo;'=&rsquo;' and level alpha test &ldquo;$\le$&rdquo; restrict c in some degree $sup_{\theta \in \theta_{0}} P(X\in R) = \alpha$, control the type 1 error</li>
</ul>
</li>
</ul>
<h3 id=most-powerful-test>Most Powerful Test</h3>
<ul>
<li>
<p>Size alpha test and level alpha test may not be unique. We need to minimize Type 2 error and control Type 1 error simultaneously</p>
</li>
<li>
<p>UMP (uniformly most powerful) test further impose hard restriction (Type 2 error) test from level alpha test.</p>
<ul>
<li>Neyman-Pearson for simple hypothesis (UMP).</li>
<li>Karlin Rubin for one-side hypothesis (UMP)</li>
<li>Non-existence for two-side hypothesis</li>
<li>Sometimes UMP does not exist, what we should do? (Two-side hypothesis)</li>
</ul>
</li>
</ul>
<h3 id=p-value>P-value</h3>
<p><strong>Definition</strong>: P-value is the probability of getting a value of test statistic that is at least as extreme as the one representing the sample data. $P(W(X)>W(x)|H_{0} \ is \ true)$</p>
<p>P value reports the test results on a continuous case, rather than a dichotomous case &lsquo;accept&rsquo; and &lsquo;reject&rsquo;</p>
<p>P-value cannot quantify Type 2 error and the definition of extremeness is vague.</p>
<p>We can construct $P(X) = sup_{\theta \in \Theta_{0}}P_{\theta}(W(X) \ge W(x))$ or $P(W(X)\ge W(x) | S(X)=S(x))$ conditioned on sufficient statistic.</p>
<h1 id=interval-estimation>Interval Estimation</h1>
<p>Every confidence set corresponds to a hypothesis test and vice versa.</p>
<h2 id=methods-of-finding-interval-estimation>Methods of finding Interval Estimation</h2>
<ul>
<li>
<p>Inverted LRT Step 1: find LRT accept region, Step 2: turn it to explicit form, Step 3: show that exist for all $\theta$</p>
</li>
<li>
<p>Pivot Quantiles</p>
</li>
</ul>
<h2 id=methods-of-evaluating-interval-estimation>Methods of Evaluating Interval Estimation</h2>
<ul>
<li>
<p>Minimize the size (length) of interval and control the coverage probability. (Solved by Lagrange multipliers with equality constraints.)</p>
</li>
<li>
<p>Decision Theory. $R(\theta,c)= E_{\theta}[L(\theta, c)]=bE_{\theta}[Length(C(X))]-P_{\theta}(\theta \in C(X))$</p>
</li>
</ul>
</div>
<div class=post-copyright>
<p class=copyright-item>
<span class=item-title>Author</span>
<span class=item-content>Tsedao</span>
</p>
<p class=copyright-item>
<span class=item-title>LastMod</span>
<span class=item-content>
2021-12-26
</span>
</p>
</div>
<footer class=post-footer>
<nav class=post-nav>
<a class=prev href=/post/docker/>
<i class="iconfont icon-left"></i>
<span class="prev-text nav-default">Docker Tutorial</span>
<span class="prev-text nav-mobile">Prev</span>
</a>
</nav>
</footer>
</article>
</div>
<script src=https://utteranc.es/client.js repo=Tsedao/tsedao.github.io issue-term=pathname theme=github-light crossorigin=anonymous async></script>
<noscript>Please enable JavaScript to view the <a href=https://github.com/utterance>comments powered by utterances.</a></noscript>
</div>
</main>
<footer id=footer class=footer>
<div class=social-links>
<a href=mailto:zitaosong@link.cuhk.edu.cn class="iconfont icon-email" title=email></a>
<a href=https://github.com/Tsedao class="iconfont icon-github" title=github></a>
<a href=https://tsedao.github.io/index.xml type=application/rss+xml class="iconfont icon-rss" title=rss></a>
</div>
<div class=copyright>
<span class=power-by>
Powered by <a class=hexo-link href=https://gohugo.io>Hugo</a>
</span>
<span class=division>|</span>
<span class=theme-info>
Theme -
<a class=theme-link href=https://github.com/olOwOlo/hugo-theme-even>Even</a>
</span>
<div class=busuanzi-footer>
<span id=busuanzi_container_site_pv> site pv: <span id=busuanzi_value_site_pv><img src=/img/spinner.svg alt=spinner.svg></span> </span>
<span class=division>|</span>
<span id=busuanzi_container_site_uv> site uv: <span id=busuanzi_value_site_uv><img src=/img/spinner.svg alt=spinner.svg></span> </span>
</div>
<span class=copyright-year>
&copy;
2021<span class=heart><i class="iconfont icon-heart"></i></span><span>Tsedao</span>
</span>
</div>
</footer>
<div class=back-to-top id=back-to-top>
<i class="iconfont icon-up"></i>
</div>
</div>
<script src=https://cdn.jsdelivr.net/npm/jquery@3.2.1/dist/jquery.min.js integrity="sha256-hwg4gsxgFZhOsEEamdOYGBf13FyQuiTwlAQgxVSNgt4=" crossorigin=anonymous></script>
<script src=https://cdn.jsdelivr.net/npm/slideout@1.0.1/dist/slideout.min.js integrity="sha256-t+zJ/g8/KXIJMjSVQdnibt4dlaDxc9zXr/9oNPeWqdg=" crossorigin=anonymous></script>
<script src=https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.js integrity="sha256-XVLffZaxoWfGUEbdzuLi7pwaUJv1cecsQJQqGLe7axY=" crossorigin=anonymous></script>
<script type=text/javascript src=/js/main.min.c99b103c33d1539acf3025e1913697534542c4a5aa5af0ccc20475ed2863603b.js></script>
<script type=text/javascript>window.MathJax={tex:{inlineMath:[['$','$'],['\\(','\\)']],tags:'ams'}}</script>
<script async src=https://cdn.jsdelivr.net/npm/mathjax@3.0.5/es5/tex-mml-chtml.js integrity="sha256-HGLuEfFcsUJGhvB8cQ8nr0gai9EucOOaIxFw7qxmd+w=" crossorigin=anonymous></script>
</body>
</html>